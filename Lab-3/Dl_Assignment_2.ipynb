{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name:  Yared Tsegaye Gizaw\n",
    "\n",
    "#### ID:  UGR/8284/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qDAEIoSGZGzU"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(inputs):\n",
    "    return torch.maximum(torch.zeros_like(inputs), inputs)\n",
    "\n",
    "def softmax(inputs):\n",
    "    exp_values = torch.exp(inputs - torch.max(inputs, dim=1, keepdim=True).values)\n",
    "    return exp_values / torch.sum(exp_values, dim=1, keepdim=True)\n",
    "\n",
    "def sigmoid(inputs):\n",
    "    return 1 / (1 + torch.exp(-inputs))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "AqxDXNTWcvHG"
   },
   "outputs": [],
   "source": [
    "# Define a Layer class that contains ReLU activation function\n",
    "\n",
    "class Activation_ReLU:\n",
    "\n",
    "  # Layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "    # Initialize weights and biases\n",
    "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
    "    self.biases = torch.zeros((1, n_neurons))\n",
    "\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    # Calculate output values from inputs, weights and biases\n",
    "    self.output = torch.matmul(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Apply activation functions\n",
    "    self.output = relu(self.output)\n",
    "#     print(self.output)\n",
    "    return self.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "3ZRaUE3SzTBt"
   },
   "outputs": [],
   "source": [
    "# Define a Layer class that contains Sigmoid activation function\n",
    "\n",
    "class Activation_Sigmoid:\n",
    "\n",
    "  # Layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "    # Initialize weights and biases\n",
    "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
    "    self.biases = torch.zeros((1, n_neurons))\n",
    "\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    # Calculate output values from inputs, weights and biases\n",
    "    self.output = torch.matmul(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Apply activation functions\n",
    "    self.output = sigmoid(self.output)\n",
    "#     print(self.output)\n",
    "    return self.output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "V0GPBFe01qWc"
   },
   "outputs": [],
   "source": [
    "# Define a Layer class that contains Softmax activation function\n",
    "\n",
    "class Activation_Softmax:\n",
    "\n",
    "  # Layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "    # Initialize weights and biases\n",
    "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
    "    self.biases = torch.zeros((1, n_neurons))\n",
    "\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    # Calculate output values from inputs, weights and biases\n",
    "    weighted_sum = torch.matmul(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Apply activation functions\n",
    "    self.output = softmax(weighted_sum)\n",
    "#     print(self.output)\n",
    "    return self.output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks With Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "GPXRPKPxAKVx"
   },
   "outputs": [],
   "source": [
    "# Create a Neural Network that uses the ReLU activation function\n",
    "\n",
    "class SimpleNeuralNetworkWithReLU:\n",
    "    def __init__(self):\n",
    "        # Define layers\n",
    "        self.layer1 = Activation_ReLU(n_inputs=4, n_neurons=18)\n",
    "        self.layer2 = Activation_ReLU(n_inputs=18, n_neurons=18)\n",
    "        self.layer3 = Activation_Softmax(n_inputs=18, n_neurons=3)  # Output layer with 3 neurons for classification\n",
    "\n",
    "    def train(self, inputs):\n",
    "        # Forward pass through each layer with manual activation functions\n",
    "        out1 = self.layer1.forward(inputs)\n",
    "        out2 = self.layer2.forward(out1)\n",
    "        log_probabilities = self.layer3.forward(out2)  # Softmax for multiclass classification\n",
    "        return log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "008gyE7MD3es"
   },
   "outputs": [],
   "source": [
    "# Create a Neural Network that uses the Sigmoid activation function\n",
    "\n",
    "class SimpleNeuralNetworkWithSigmoid:\n",
    "    def __init__(self):\n",
    "        # Define layers\n",
    "        self.layer1 = Activation_Sigmoid(n_inputs=4, n_neurons=18)\n",
    "        self.layer2 = Activation_Sigmoid(n_inputs=18, n_neurons=18)\n",
    "        self.layer3 = Activation_Softmax(n_inputs=18, n_neurons=3)  # Output layer with 3 neurons for classification\n",
    "\n",
    "    def train(self, inputs):\n",
    "        # Forward pass through each layer with manual activation functions\n",
    "        out1 = self.layer1.forward(inputs)\n",
    "        out2 = self.layer2.forward(out1)\n",
    "        log_probabilities = self.layer3.forward(out2)  # Softmax for multiclass classification\n",
    "        return log_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdEwRDpcLp7c"
   },
   "source": [
    "#### Cross Entropy Loss & Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "8cNfpQDDVG_Y"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(predictions, targets):\n",
    "    predictions_clipped = torch.clamp(predictions, 1e-7, 1 - 1e-7)\n",
    "    log_likelihoods = -torch.sum(targets * torch.log(predictions_clipped))\n",
    "    return log_likelihoods\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "  pred_index = torch.argmax(predictions, axis=1)\n",
    "  correct_predictions = torch.sum(pred_index == targets).item()\n",
    "  accuracy = correct_predictions / len(targets)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare ReLU and Sigmoid Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "VtTS4sV8MLr_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5615, 0.1774, 0.8147, 0.3295],\n",
       "         [0.2319, 0.7832, 0.8544, 0.1012],\n",
       "         [0.1877, 0.9310, 0.0899, 0.3156],\n",
       "         [0.9423, 0.2536, 0.7388, 0.5404],\n",
       "         [0.4356, 0.4430, 0.6257, 0.0379]]),\n",
       " tensor([1, 0, 2, 0, 1]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(20)\n",
    "input = torch.rand(5, 4)\n",
    "targets = torch.tensor([1, 0, 2, 0, 1])\n",
    "input, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfrxK8FXNupP"
   },
   "source": [
    "#### Test ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYhC5mv4LtWs",
    "outputId": "02e81575-25c0-4ef6-d072-5340045ad16f"
   },
   "outputs": [],
   "source": [
    "def relu_test():\n",
    "    model_relu = SimpleNeuralNetworkWithReLU()\n",
    "    relu_predictions = model_relu.train(input)\n",
    "    loss = cross_entropy_loss(relu_predictions, targets)\n",
    "    acc = accuracy(relu_predictions, targets)\n",
    "    \n",
    "    print(\"================ReLU Test===============\")\n",
    "    print(\"The Cross Entropy Loss is: \", loss)\n",
    "    print(\"the accuracy is: \", acc)\n",
    "\n",
    "def sigmoid_test():\n",
    "    model_sigmoid = SimpleNeuralNetworkWithSigmoid()\n",
    "    sigmoid_predictions = model_sigmoid.train(input)\n",
    "    loss = cross_entropy_loss(relu_predictions, targets)\n",
    "    acc = accuracy(relu_predictions, targets)\n",
    "    \n",
    "    print(\"\\n\\n================Sigmoid Test===============\")\n",
    "    print(\"The Cross Entropy Loss is: \", loss)\n",
    "    print(\"the accuracy is: \", acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT0ijyF5NyqZ"
   },
   "source": [
    "#### Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhNExD4PMNE1",
    "outputId": "5eb6405d-297b-45b4-823d-c2d82b3dce39",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrelu_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m sigmoid_test()\n",
      "Cell \u001b[1;32mIn[89], line 4\u001b[0m, in \u001b[0;36mrelu_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model_relu \u001b[38;5;241m=\u001b[39m SimpleNeuralNetworkWithReLU()\n\u001b[0;32m      3\u001b[0m relu_predictions \u001b[38;5;241m=\u001b[39m model_relu\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelu_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(relu_predictions, targets)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m================ReLU Test===============\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[87], line 3\u001b[0m, in \u001b[0;36mcross_entropy_loss\u001b[1;34m(predictions, targets)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcross_entropy_loss\u001b[39m(predictions, targets):\n\u001b[0;32m      2\u001b[0m     predictions_clipped \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(predictions, \u001b[38;5;241m1e-7\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1e-7\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     log_likelihoods \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_clipped\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihoods\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "relu_test()\n",
    "sigmoid_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOt9s5-EOUPA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
