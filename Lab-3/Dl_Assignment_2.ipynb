{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name:  Yared Tsegaye Gizaw\n",
    "\n",
    "#### ID:  UGR/8284/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qDAEIoSGZGzU"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(inputs):\n",
    "    return torch.maximum(torch.zeros_like(inputs), inputs)\n",
    "\n",
    "def softmax(inputs):\n",
    "    exp_values = torch.exp(inputs - torch.max(inputs, dim=1, keepdim=True).values)\n",
    "    return exp_values / torch.sum(exp_values, dim=1, keepdim=True)\n",
    "\n",
    "def sigmoid(inputs):\n",
    "    return 1 / (1 + torch.exp(-inputs))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AqxDXNTWcvHG"
   },
   "outputs": [],
   "source": [
    "# Define a Layer class that contains ReLU activation function\n",
    "\n",
    "class Activation_ReLU:\n",
    "\n",
    "  # Layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "    # Initialize weights and biases\n",
    "    self.weights = torch.rand((n_inputs, n_neurons), requires_grad=True)\n",
    "    self.biases = torch.zeros((1, n_neurons), requires_grad=True)\n",
    "\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    # Calculate output values from inputs, weights and biases\n",
    "    self.output = torch.matmul(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Apply activation functions\n",
    "    self.output = relu(self.output)\n",
    "#     print(self.output)\n",
    "    return self.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3ZRaUE3SzTBt"
   },
   "outputs": [],
   "source": [
    "# Define a Layer class that contains Sigmoid activation function\n",
    "\n",
    "class Activation_Sigmoid:\n",
    "\n",
    "  # Layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "    # Initialize weights and biases\n",
    "    self.weights = torch.rand((n_inputs, n_neurons), requires_grad=True)\n",
    "    self.biases = torch.zeros((1, n_neurons), requires_grad=True)\n",
    "\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    # Calculate output values from inputs, weights and biases\n",
    "    self.output = torch.matmul(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Apply activation functions\n",
    "    self.output = sigmoid(self.output)\n",
    "#     print(self.output)\n",
    "    return self.output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V0GPBFe01qWc"
   },
   "outputs": [],
   "source": [
    "# Define a Layer class that contains Softmax activation function\n",
    "\n",
    "class Activation_Softmax:\n",
    "\n",
    "  # Layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "    # Initialize weights and biases\n",
    "    self.weights = torch.rand((n_inputs, n_neurons), requires_grad=True)\n",
    "    self.biases = torch.zeros((1, n_neurons), requires_grad=True)\n",
    "\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    # Calculate output values from inputs, weights and biases\n",
    "    weighted_sum = torch.matmul(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Apply activation functions\n",
    "    self.output = softmax(weighted_sum)\n",
    "#     print(self.output)\n",
    "    return self.output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks With Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GPXRPKPxAKVx"
   },
   "outputs": [],
   "source": [
    "# Create a Neural Network that uses the ReLU activation function\n",
    "\n",
    "class SimpleNeuralNetworkWithReLU:\n",
    "    def __init__(self):\n",
    "        # Define layers\n",
    "        self.layer1 = Activation_ReLU(n_inputs=4, n_neurons=18)\n",
    "        self.layer2 = Activation_ReLU(n_inputs=18, n_neurons=18)\n",
    "        self.layer3 = Activation_Softmax(n_inputs=18, n_neurons=3)  # Output layer with 3 neurons for classification\n",
    "\n",
    "    def train(self, inputs):\n",
    "        # Forward pass through each layer with manual activation functions\n",
    "        out1 = self.layer1.forward(inputs)\n",
    "        out2 = self.layer2.forward(out1)\n",
    "        log_probabilities = self.layer3.forward(out2)  # Softmax for multiclass classification\n",
    "        return log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "008gyE7MD3es"
   },
   "outputs": [],
   "source": [
    "# Create a Neural Network that uses the Sigmoid activation function\n",
    "\n",
    "class SimpleNeuralNetworkWithSigmoid:\n",
    "    def __init__(self):\n",
    "        # Define layers\n",
    "        self.layer1 = Activation_Sigmoid(n_inputs=4, n_neurons=18)\n",
    "        self.layer2 = Activation_Sigmoid(n_inputs=18, n_neurons=18)\n",
    "        self.layer3 = Activation_Softmax(n_inputs=18, n_neurons=3)  # Output layer with 3 neurons for classification\n",
    "\n",
    "    def train(self, inputs):\n",
    "        # Forward pass through each layer with manual activation functions\n",
    "        out1 = self.layer1.forward(inputs)\n",
    "        out2 = self.layer2.forward(out1)\n",
    "        log_probabilities = self.layer3.forward(out2)  # Softmax for multiclass classification\n",
    "        return log_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdEwRDpcLp7c"
   },
   "source": [
    "#### Cross Entropy Loss & Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8cNfpQDDVG_Y"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(predictions, targets):\n",
    "  size = predictions.shape[0]\n",
    "  input_losses = -torch.log(predictions[range(size), targets])\n",
    "  loss = torch.sum(input_losses) / size\n",
    "  return loss\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "  pred_index = torch.argmax(predictions, axis=1)\n",
    "  correct_predictions = torch.sum(pred_index == targets).item()\n",
    "  accuracy_val = correct_predictions / len(targets)\n",
    "  return accuracy_val, pred_index == targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare ReLU and Sigmoid Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VtTS4sV8MLr_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5615, 0.1774, 0.8147, 0.3295],\n",
       "         [0.2319, 0.7832, 0.8544, 0.1012],\n",
       "         [0.1877, 0.9310, 0.0899, 0.3156],\n",
       "         [0.9423, 0.2536, 0.7388, 0.5404],\n",
       "         [0.4356, 0.4430, 0.6257, 0.0379]]),\n",
       " tensor([0, 1, 0, 2, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(20)\n",
    "input = torch.rand(5, 4)\n",
    "targets = torch.tensor([0, 1, 0, 2, 1])\n",
    "input, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfrxK8FXNupP"
   },
   "source": [
    "#### Test ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYhC5mv4LtWs",
    "outputId": "02e81575-25c0-4ef6-d072-5340045ad16f"
   },
   "outputs": [],
   "source": [
    "def relu_test():\n",
    "    model_relu = SimpleNeuralNetworkWithReLU()\n",
    "    relu_predictions = model_relu.train(input)\n",
    "    loss = cross_entropy_loss(relu_predictions, targets)\n",
    "    accuracy_val, preds = accuracy(relu_predictions, targets)\n",
    "    print(\"================ReLU Test===============\")\n",
    "    print(\"The Cross Entropy Loss is: \", loss.item())\n",
    "    print(\"the accuracy is: \", accuracy_val)\n",
    "    print(preds)\n",
    "\n",
    "def sigmoid_test():\n",
    "    model_sigmoid = SimpleNeuralNetworkWithSigmoid()\n",
    "    sigmoid_predictions = model_sigmoid.train(input)\n",
    "    loss = cross_entropy_loss(sigmoid_predictions, targets)\n",
    "    accuracy_val, preds = accuracy(sigmoid_predictions, targets)\n",
    "    \n",
    "    print(\"\\n\\n================Sigmoid Test===============\")\n",
    "    print(\"The Cross Entropy Loss is: \", loss.item())\n",
    "    print(\"the accuracy is: \", accuracy_val)\n",
    "    print(preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT0ijyF5NyqZ"
   },
   "source": [
    "#### Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhNExD4PMNE1",
    "outputId": "5eb6405d-297b-45b4-823d-c2d82b3dce39",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ReLU Test===============\n",
      "The Cross Entropy Loss is:  14.831993103027344\n",
      "the accuracy is:  0.2\n",
      "tensor([False, False, False,  True, False])\n",
      "\n",
      "\n",
      "================Sigmoid Test===============\n",
      "The Cross Entropy Loss is:  1.161668300628662\n",
      "the accuracy is:  0.4\n",
      "tensor([False,  True, False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "relu_test()\n",
    "sigmoid_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
