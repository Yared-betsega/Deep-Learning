{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e4e31f",
   "metadata": {},
   "source": [
    "### Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7314077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\envy 12th\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from PIL import Image\n",
    "from torch import nn, save, load\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ecf2b5",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aa4f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: Dataset ImageFolder\n",
      "    Number of datapoints: 30106\n",
      "    Root location: dataset/training_data\n",
      "    StandardTransform\n",
      "Transform: ToTensor() files\n"
     ]
    }
   ],
   "source": [
    "train = datasets.ImageFolder(root=\"dataset/training_data\", transform=ToTensor())\n",
    "dataset = DataLoader(train, batch_size=32, shuffle=True)\n",
    "print(f\"Data loaded: {dataset.dataset} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ba6cb",
   "metadata": {},
   "source": [
    "### Split the data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3a4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = \"data_copy\"\n",
    "\n",
    "# Set the path to the training and test data folders\n",
    "training_data_path = \"training_data\"\n",
    "test_data_path = \"test_data\"\n",
    "\n",
    "# Set the ratio for splitting the data (80% for training, 20% for testing)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Create the training and test data folders if they don't exist\n",
    "os.makedirs(training_data_path, exist_ok=True)\n",
    "os.makedirs(test_data_path, exist_ok=True)\n",
    "\n",
    "# Iterate through the characters in the dataset\n",
    "for char_folder in os.listdir(dataset_path):\n",
    "    char_folder_path = os.path.join(dataset_path, char_folder)\n",
    "    if os.path.isdir(char_folder_path):\n",
    "        # Get the list of image files in the character folder\n",
    "        image_files = os.listdir(char_folder_path)\n",
    "\n",
    "        # Shuffle the image files randomly\n",
    "        random.shuffle(image_files)\n",
    "\n",
    "        # Calculate the split index based on the split ratio\n",
    "        split_index = int(len(image_files) * split_ratio)\n",
    "\n",
    "        # Split the image files into training and test data\n",
    "        training_files = image_files[:split_index]\n",
    "        test_files = image_files[split_index:]\n",
    "\n",
    "        # Move the training files to the training data folder\n",
    "        for file in training_files:\n",
    "            src = os.path.join(char_folder_path, file)\n",
    "            dst = os.path.join(training_data_path, char_folder, file)\n",
    "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "        # Move the test files to the test data folder\n",
    "        for file in test_files:\n",
    "            src = os.path.join(char_folder_path, file)\n",
    "            dst = os.path.join(test_data_path, char_folder, file)\n",
    "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "            shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded23d82",
   "metadata": {},
   "source": [
    "### Define the image classifier Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "188e9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(64*(28-6)*(28-6), 34)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcff081",
   "metadata": {},
   "source": [
    "### Instance of the neural network, loss, optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63ae842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ImageClassifier().to('cpu')\n",
    "opt = Adam(clf.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fd078",
   "metadata": {},
   "source": [
    "### Training flow \n",
    "\n",
    "- I trained the model for 10 epochs and printed the loss at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cda0bd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 loss is 0.0\n",
      "Epoch:1 loss is 0.0\n",
      "Epoch:2 loss is 0.0\n",
      "Epoch:3 loss is 0.0\n",
      "Epoch:4 loss is 0.0\n",
      "Epoch:5 loss is 0.0\n",
      "Epoch:6 loss is 0.0\n",
      "Epoch:7 loss is 0.0\n",
      "Epoch:8 loss is 0.0\n",
      "Epoch:9 loss is 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): # train for 10 epochs\n",
    "    for batch in dataset: \n",
    "        X,y = batch \n",
    "        X, y = X.to('cpu'), y.to('cpu') \n",
    "        yhat = clf(X) \n",
    "        loss = loss_fn(yhat, y) \n",
    "\n",
    "        # Apply backprop \n",
    "        opt.zero_grad()\n",
    "        loss.backward() \n",
    "        opt.step() \n",
    "\n",
    "    print(f\"Epoch:{epoch} loss is {loss.item()}\")\n",
    "\n",
    "with open('trained_model.pt', 'wb') as f: \n",
    "    save(clf.state_dict(), f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bfd040",
   "metadata": {},
   "source": [
    "## Testing the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1474a4e",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77187304",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_model.pt', 'rb') as f: \n",
    "    clf.load_state_dict(load(f)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921284f",
   "metadata": {},
   "source": [
    "### Load a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fe0ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted character is ኘ\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('ኞ.jpg')\n",
    "img.convert('RGB')\n",
    "img_tensor = F.to_tensor(img)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "img_tensor = img_tensor.expand(3, 3, img_tensor.shape[2], img_tensor.shape[3])\n",
    "\n",
    "amharic_chars = ['ሀ', 'ለ', 'ሐ', 'መ', 'ሠ', 'ረ', 'ሰ', 'ሸ', 'ቀ', 'በ', 'ቨ', 'ተ', 'ቸ', 'ኀ', 'ነ', 'ኘ', 'አ', 'ከ', 'ኸ', 'ወ', 'ዐ', 'ዘ', 'ዠ', 'የ', 'ደ', 'ጀ', 'ገ', 'ጠ', 'ጨ', 'ጰ', 'ጸ', 'ፀ', 'ፈ', 'ፐ']\n",
    "\n",
    "predicted_character_index = torch.argmax(clf(img_tensor))\n",
    "predicted_character = amharic_chars[predicted_character_index]\n",
    "print(f\"The predicted character is {predicted_character}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be02c9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted character is ቀ\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0330a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
