{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qDAEIoSGZGzU"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Layer class that contains ReLU activation function\n",
        "\n",
        "class Activation_ReLU:\n",
        "\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = torch.matmul(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Apply activation functions\n",
        "    self.output = torch.max(torch.tensor(0.0), self.output)\n",
        "    return self.output\n"
      ],
      "metadata": {
        "id": "AqxDXNTWcvHG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Layer class that contains Sigmoid activation function\n",
        "\n",
        "class Activation_Sigmoid:\n",
        "\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = torch.matmul(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Apply activation functions\n",
        "    self.output = 1 / (1 + torch.exp(-self.output))\n",
        "\n",
        "    return self.output\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZRaUE3SzTBt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Layer class that contains Softmax activation function\n",
        "\n",
        "class Activation_Softmax:\n",
        "\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    multiplied_inputs = torch.matmul(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Apply activation functions\n",
        "    exp_values = torch.exp(multiplied_inputs) - torch.max(inputs, axis=1,keepdims=True).values\n",
        "    summed_input = exp_values.sum(dim=1, keepdim=True)\n",
        "    probabilities = exp_values / summed_input\n",
        "    self.output = probabilities\n",
        "\n",
        "    return self.output\n"
      ],
      "metadata": {
        "id": "V0GPBFe01qWc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Neural Network that uses the ReLU activation function\n",
        "\n",
        "class SimpleNeuralNetworkWithReLU:\n",
        "    def __init__(self):\n",
        "        # Define layers\n",
        "        self.layer1_relu = Activation_ReLU(n_inputs=4, n_neurons=18)\n",
        "        self.layer2_relu = Activation_ReLU(n_inputs=18, n_neurons=18)\n",
        "        self.layer3_softmax = Activation_Softmax(n_inputs=18, n_neurons=3)  # Output layer with 3 neurons for classification\n",
        "\n",
        "    def train(self, inputs):\n",
        "        # Forward pass through each layer with manual activation functions\n",
        "        out1 = self.layer1_relu.forward(inputs)\n",
        "        out2 = self.layer2_relu.forward(out1)\n",
        "        log_probabilities = self.layer3_softmax.forward(out2)  # Softmax for multiclass classification\n",
        "        return log_probabilities"
      ],
      "metadata": {
        "id": "GPXRPKPxAKVx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Neural Network that uses the Sigmoid activation function\n",
        "\n",
        "class SimpleNeuralNetworkWithSigmoid:\n",
        "    def __init__(self):\n",
        "        # Define layers\n",
        "        self.layer1 = Activation_Sigmoid(n_inputs=4, n_neurons=18)\n",
        "        self.layer2 = Activation_Sigmoid(n_inputs=18, n_neurons=18)\n",
        "        self.layer3 = Activation_Softmax(n_inputs=18, n_neurons=3)  # Output layer with 3 neurons for classification\n",
        "\n",
        "    def train(self, inputs):\n",
        "        # Forward pass through each layer with manual activation functions\n",
        "        out1 = self.layer1.forward(inputs)\n",
        "        out2 = self.layer2.forward(out1)\n",
        "        log_probabilities = self.layer3.forward(out2)  # Softmax for multiclass classification\n",
        "        return log_probabilities"
      ],
      "metadata": {
        "id": "008gyE7MD3es"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model that uses the ReLU activation function for the first two layer of the neural network."
      ],
      "metadata": {
        "id": "DHZBnGdWEeob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu = SimpleNeuralNetworkWithReLU()\n",
        "input = torch.rand(2, 4)\n",
        "print(input)\n",
        "output = model_relu.train(input)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UQv3eH3EnSX",
        "outputId": "cb928f37-0aa5-4073-b031-f3d7833cc91e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8317, 0.8812, 0.4141, 0.2984],\n",
            "        [0.2336, 0.9730, 0.7667, 0.0312]])\n",
            "tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigmoid = SimpleNeuralNetworkWithSigmoid()\n",
        "input2 = torch.rand(2, 4)\n",
        "print(input2)\n",
        "output2 = model_sigmoid.train(input2)\n",
        "print(output2)"
      ],
      "metadata": {
        "id": "WxIzHlWAHIun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b416c3-8af5-403d-fef3-05d45a86a754"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1018, 0.4859, 0.2624, 0.8219],\n",
            "        [0.3243, 0.4467, 0.0189, 0.2700]])\n",
            "tensor([[0.3335, 0.3379, 0.3287],\n",
            "        [0.3335, 0.3379, 0.3287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "9"
      ],
      "metadata": {
        "id": "uvfSiUKELVzV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Cross Entropy Loss\n"
      ],
      "metadata": {
        "id": "hdEwRDpcLp7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(predictions, targets):\n",
        "  size = predictions.shape[0]\n",
        "  input_losses = -torch.log(predictions[range(size), targets])\n",
        "  loss = torch.sum(input_losses) / size\n",
        "  return loss\n",
        "\n",
        "def accuracy(predictions, targets):\n",
        "  pred_index = torch.argmax(predictions, axis=1)\n",
        "  correct_predictions = torch.sum(pred_index == targets).item()\n",
        "  accuracy = correct_predictions / len(targets)\n",
        "  print(pred_index == correct_predictions)\n",
        "  print(\"The number of correct predictions is: \", correct_predictions)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "8cNfpQDDVG_Y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.rand(5, 4)\n",
        "targets = torch.tensor([1, 0, 2, 0, 1])"
      ],
      "metadata": {
        "id": "VtTS4sV8MLr_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test ReLU activation function"
      ],
      "metadata": {
        "id": "kfrxK8FXNupP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relu_predictions = model_relu.train(input)\n",
        "\n",
        "loss = cross_entropy_loss(relu_predictions, targets)\n",
        "print(\"The Cross Entropy Loss is: \", loss)\n",
        "\n",
        "acc = accuracy(relu_predictions, targets)\n",
        "print(\"the accuracy is: \", acc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYhC5mv4LtWs",
        "outputId": "02e81575-25c0-4ef6-d072-5340045ad16f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross Entropy Loss is:  tensor(1.0986)\n",
            "tensor([False, False, False, False, False])\n",
            "The number of correct predictions is:  2\n",
            "the accuracy is:  0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test Sigmoid Activation Function"
      ],
      "metadata": {
        "id": "ZT0ijyF5NyqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid_predictions = model_sigmoid.train(input)\n",
        "\n",
        "loss = cross_entropy_loss(relu_predictions, targets)\n",
        "print(\"The Cross Entropy Loss is: \", loss)\n",
        "\n",
        "acc = accuracy(relu_predictions, targets)\n",
        "print(\"the accuracy is: \", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhNExD4PMNE1",
        "outputId": "5eb6405d-297b-45b4-823d-c2d82b3dce39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross Entropy Loss is:  tensor(1.0986)\n",
            "tensor([False, False, False, False, False])\n",
            "The number of correct predictions is:  2\n",
            "the accuracy is:  0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "sigmoid_predictions = model_sigmoid.train(input)\n",
        "# Use CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(sigmoid_predictions)\n",
        "# Calculate the loss\n",
        "loss = criterion(sigmoid_predictions, targets)\n",
        "loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5PGP09pN37S",
        "outputId": "89017f92-4dac-434e-cf77-b3bb84b2de45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3286, 0.3433, 0.3281],\n",
            "        [0.3286, 0.3433, 0.3281],\n",
            "        [0.3286, 0.3433, 0.3281],\n",
            "        [0.3286, 0.3433, 0.3281],\n",
            "        [0.3286, 0.3433, 0.3281]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0976)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOt9s5-EOUPA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mVpTCY8SSoDq"
      }
    }
  ]
}